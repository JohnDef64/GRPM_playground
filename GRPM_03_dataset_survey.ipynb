{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRPM MeSH Screening \n",
    "\n",
    "This notebook is engineered to screen the previously retrieved genetic polymorphism data using selected MeSH terms. It works with MeSH sets that are used as hooks to retrieve subsets of genes and polymorphisms from the \"GRPM ds\" dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Only for Google Colab\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# @markdown Run in Colab virtual machine by default\n",
    "\n",
    "# @markdown to run in google drive set:\n",
    "import_mydrive = False #@param {type:\"boolean\"}\n",
    "\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    subprocess.run([\"pip\", \"install\", \"nbib\"])\n",
    "    subprocess.run([\"pip\", \"install\", \"biopython\"])\n",
    "\n",
    "    if import_mydrive:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "\n",
    "        if not os.path.exists('/content/drive/MyDrive/grpm_system/'):\n",
    "            subprocess.run(['mkdir', '/content/drive/MyDrive/grpm_system/'])\n",
    "        subprocess.run(['cd', '/content/drive/MyDrive/grpm_system/'])\n",
    "    else:\n",
    "        if not os.path.exists('/content/grpm_system/'):\n",
    "            subprocess.run(['mkdir', '/content/grpm_system/'])\n",
    "        subprocess.run(['cd', '/content/grpm_system/'])\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "print(\"Current working directory:\", current_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import glob\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "def simple_bool(message):\n",
    "    choose = input(message+\" (y/n): \").lower()\n",
    "    your_bool = choose in [\"y\", \"yes\",\"yea\",\"sure\"]\n",
    "    return your_bool\n",
    "\n",
    "def get_and_extract(file, dir = os.getcwd()):\n",
    "    url = \"https://zenodo.org/record/8205724/files/\"+file+\".zip?download=1\"\n",
    "    zip_file_name = file+\".zip\"\n",
    "    extracted_folder_name = dir\n",
    "\n",
    "    # Download the ZIP file\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        # Extract the ZIP contents\n",
    "        with io.BytesIO(response.content) as zip_buffer:\n",
    "            with zipfile.ZipFile(zip_buffer, 'r') as zip_ref:\n",
    "                zip_ref.extractall(extracted_folder_name)\n",
    "        print(f\"ZIP file '{zip_file_name}' extracted to '{extracted_folder_name}' successfully.\")\n",
    "    else:\n",
    "        print(\"Failed to download the ZIP file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get GRPM Dataset from Zenodo Repository\n",
    "#https://zenodo.org/record/8205724  DOI: 10.5281/zenodo.8205724\n",
    "\n",
    "if simple_bool('Download pre-made GRPM-Dataset from Zenodo? (6.5 minutes in Colab)'):\n",
    "    timea = datetime.now()\n",
    "    get_and_extract('grpm_dataset')\n",
    "    print('Download and extraction time ',datetime.now()-timea)\n",
    "\n",
    "if simple_bool('Download pre-made ref-mesh-archive from Zenodo?'):\n",
    "    timea = datetime.now()\n",
    "    get_and_extract('ref-mesh-archive')\n",
    "    print('Download and extraction time ',datetime.now()-timea)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import GRPM dataset (required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load GRPM db Report-----------------------------------------\n",
    "\n",
    "# choose database:\n",
    "db_tag      = 'pcg'\n",
    "# 'pcg'    = protein coding genes = grpm_db\n",
    "# 'rna'    = rna genes            = grpm_db_rna\n",
    "# 'pseudo' = pseudogenes          = grpm_db_pseudo\n",
    "\n",
    "db_name = 'grpm_db_'+ db_tag\n",
    "db_path = 'grpm_dataset/'+db_name\n",
    "\n",
    "print('importing GRPM Dataset...')\n",
    "#get gene list from grpm report\n",
    "GRPM_report = pd.read_csv(db_path+'/GRPM_report.csv',index_col=0).transpose().reset_index().rename(columns={'index':'gene'})\n",
    "grpm_genes_list = GRPM_report.gene.to_list()\n",
    "\n",
    "#Import grpm data back-------------------------------------------\n",
    "time_load_1 = datetime.now()\n",
    "\n",
    "columns = ['gene', 'rsid', 'pmids', 'mesh']\n",
    "grpm_dataset = pd.read_csv(db_path+'/grpm_table_output.csv', usecols=columns)\n",
    "\n",
    "grpm_dataset['pmids'] = grpm_dataset['pmids'].astype(str) #convert pmid type in str\n",
    "time_load_2 = datetime.now()\n",
    "print('time load:',time_load_2-time_load_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset GRPM Dataset (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subset_grpm = simple_bool('Do you want to use a custom gene list to subset GRPM Dataset?')\n",
    "if subset_grpm:\n",
    "    # import your custom gene list (.csv)\n",
    "    file_csv = []\n",
    "    for file in os.listdir():\n",
    "        if file.endswith(\".csv\") or file.endswith(\".tsv\"):\n",
    "            file_csv.append(file)\n",
    "\n",
    "    filenum = input('import your custom gene list (.csv)\\nselect file index: \\n'+str(pd.Series(file_csv)))\n",
    "\n",
    "    time1 = datetime.now()\n",
    "    subset_genes = pd.read_csv(file_csv[int(filenum)])\n",
    "    subset_genes = subset_genes[subset_genes.columns[int(input('select column index:\\n'+ str(pd.Series(subset_genes.columns))))]].drop_duplicates().str.replace(' ','')\n",
    "    subset_genes.to_list()\n",
    "\n",
    "    # subsetting GRPM_report and grpm_dataset\n",
    "    GRPM_report_subset = GRPM_report[GRPM_report['gene'].isin(subset_genes)]\n",
    "    grpm_subset = grpm_dataset[grpm_dataset['gene'].isin(subset_genes)]\n",
    "    print(\"You're using a GRPM Dataset partition\\ntime subsetting:\",time_load_2-time_load_1)\n",
    "    display(GRPM_report_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define context\n",
    "    - gene list\n",
    "    - survey directory\n",
    "    - ref-mesh list"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Check avalable ref-MeSH lists\n",
    "## Set directory/import data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Check avalable refs:\n",
    "ref_path = \"ref-mesh-archive/\"  # Replace with the actual ref mesh path\n",
    "\n",
    "#---------------------------------\n",
    "#use random mesh list?\n",
    "random_mesh = False\n",
    "if random_mesh:\n",
    "    ref_path = \"ref-mesh-archive/random_lists/\"\n",
    "#---------------------------------\n",
    "\n",
    "# Create a file path pattern to match CSV files\n",
    "file_pattern = os.path.join(ref_path, \"*.csv\")\n",
    "\n",
    "# Use glob to get a list of file paths matching the pattern\n",
    "csv_files = glob.glob(file_pattern)\n",
    "\n",
    "csv_files_name = []\n",
    "# Print the list of CSV files\n",
    "for file in csv_files:\n",
    "    file_name = os.path.basename(file)\n",
    "    csv_files_name.append(file_name)\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "print('Available reference mesh lists:')\n",
    "csv_files_df = pd.Series(csv_files_name)\n",
    "\n",
    "csv_file_tag = pd.DataFrame()\n",
    "if not random_mesh:\n",
    "    csv_file_tag = csv_files_df.str.extract(r'ref_mesh_(.*)\\.csv', expand=False).dropna().reset_index(drop=True)\n",
    "else:\n",
    "    csv_file_tag = csv_files_df.str.extract(r'(.*)\\.csv', expand=False).dropna().reset_index(drop=True)\n",
    "\n",
    "\n",
    "#------------------------------------------------------\n",
    "# define directory folder path:\n",
    "survey_path = 'grpm_surveys/' # keep default to use root path\n",
    "\n",
    "# choose ref_mesh.csv tab:\n",
    "topic_tag   = csv_file_tag[int(input('\\Select index from available ref-mesh list:\\n'+str(csv_file_tag)))]\n",
    "add         = ''    # additional survey directory tag\n",
    "#------------------------------------------------------\n",
    "\n",
    "\n",
    "# (1) Create survey directory:\n",
    "survey_path = survey_path+'grpm_random/' if random_mesh else survey_path\n",
    "directory = survey_path + 'grpm_survey_' + db_tag + '_' + topic_tag + add\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "\n",
    "# (2) Import Mesh-reference list:\n",
    "ref_filename = \"ref_mesh_\" + topic_tag + \".csv\" if not random_mesh else topic_tag + \".csv\"\n",
    "ref = pd.read_csv(ref_path + ref_filename, index_col=0)\n",
    "\n",
    "if 'mesh' not in ref.columns:\n",
    "    ref = ref.rename(columns={'Preferred Label': 'mesh'})\n",
    "\n",
    "ref_mesh_n = ref.mesh.nunique()\n",
    "ref_mesh_list = ref['mesh'].drop_duplicates()\n",
    "\n",
    "\n",
    "#if os.path.isfile(directory+'/GRPMX_report.csv'):\n",
    "#    df_report_complete = pd.read_csv(directory+'/GRPMX_report.csv',index_col=0)\n",
    "#    restart = Truedb_tag\n",
    "#else:\n",
    "#    df_report_complete = pd.DataFrame()\n",
    "#    restart = False\n",
    "\n",
    "#----------------------------------------------------------\n",
    "print('\\n', ref_mesh_list)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check checkpoint report:\n",
    "df_report_complete.T.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# GRPM dataset Preprocessing\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "# Preprocessing: mesh filering\n",
    "time_1 = datetime.now()\n",
    "genes = grpm_dataset.gene.drop_duplicates().to_list()\n",
    "\n",
    "mask_full = grpm_dataset['mesh'].isin(ref_mesh_list)\n",
    "grpm_match_full = grpm_dataset[mask_full].drop_duplicates()\n",
    "\n",
    "# save GRPM_gene\n",
    "grpm_match_full[['gene', 'rsid', 'pmids', 'mesh']].to_csv(directory+'/grpmx_filtered_output.csv')\n",
    "print(datetime.now() -time_1)\n",
    "\n",
    "# GET GRPM whole dataset Metrics\n",
    "time_1 = datetime.now()\n",
    "grpm_dataset['pmidmesh'] = grpm_dataset['pmids']+grpm_dataset['mesh']\n",
    "print(datetime.now() -time_1)\n",
    "grpm_dataset.head()\n",
    "\n",
    "time_1 = datetime.now()\n",
    "grpm_gene_metrics = grpm_dataset[['gene', 'rsid', 'pmids', 'mesh', 'pmidmesh']].groupby('gene').describe(include='all')#agg(lambda x: x.unique())\n",
    "print(datetime.now() -time_1)\n",
    "grpm_gene_metrics.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "0:00:57.947976 x 3\n",
    "0:01:14.471060 x 4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Run Survey"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "#---------------------------------------------\n",
    "# Edit saving options:\n",
    "checkpoint = 500 #save data each x genes\n",
    "\n",
    "run_sample = False # set True just to run a test\n",
    "num_sample = 10\n",
    "\n",
    "exclude_top10 = True # for a faster job\n",
    "save_plot = False  # only if exclude_top10 = False\n",
    "\n",
    "df_report_complete = pd.DataFrame()\n",
    "restart = False\n",
    "#---------------------------------------------\n",
    "\n",
    "if restart:\n",
    "    restart_from = len(df_report_complete.T)\n",
    "    gene_start = restart_from\n",
    "    print('search restarted from '+str(restart_from))\n",
    "else:\n",
    "    gene_start = 0\n",
    "\n",
    "# Define grpm subset\n",
    "if 'subset_grpm' in locals() and subset_grpm:\n",
    "    GRPM_report = GRPM_report_subset\n",
    "    grpm_dataset = grpm_subset\n",
    "\n",
    "# define gene list\n",
    "import random\n",
    "if run_sample:\n",
    "    genes = random.sample(grpm_genes_list[:], num_sample)\n",
    "else:\n",
    "    genes = grpm_genes_list[gene_start:len(grpm_genes_list)]\n",
    "\n",
    "for gene in tqdm(genes):\n",
    "\n",
    "    time_alpha = datetime.now()\n",
    "    timestamp = time_alpha.strftime('%Y%m%d%H%M%S')\n",
    "\n",
    "    #grpm_gene = grpm_dataset.loc[grpm_dataset['gene'] == gene]\n",
    "    grpm_gene = grpm_match_full.loc[grpm_match_full['gene'] == gene]\n",
    "    #print(datetime.now() -time_alpha)\n",
    "\n",
    "    # subset on \"grpm_gene\"------------------------\n",
    "    dfmatch_full = grpm_gene\n",
    "    dfmatch_less = dfmatch_full[['pmids', 'rsid', 'mesh']].drop_duplicates()\n",
    "    \n",
    "\n",
    "    # Pre-Selection Metrics ===========\n",
    "    grpm_pmid_gene = grpm_gene_metrics.loc[gene]\n",
    "    starting_pmid     =  grpm_pmid_gene.pmids.loc['unique']\n",
    "    starting_mesh     =  grpm_pmid_gene.mesh.loc['unique']\n",
    "    lit1_rsid         =  grpm_pmid_gene.rsid.loc['unique']\n",
    "    starting_pmidmesh =  grpm_pmid_gene.pmidmesh.loc['unique']\n",
    "    \n",
    "    #  Post-Selection Metrics ===========\n",
    "    matching_rsid     = dfmatch_full['rsid'].nunique()\n",
    "    dropped_rsid      = lit1_rsid - dfmatch_full['rsid'].nunique()\n",
    "   \n",
    "    matching_pmids    = dfmatch_less.pmids.nunique()\n",
    "    matching_mesh     = dfmatch_less.mesh.nunique()\n",
    "    matching_pmidmesh = len(dfmatch_less[['pmids','mesh']].drop_duplicates())\n",
    "\n",
    "    #------------------------\n",
    "    if exclude_top10:\n",
    "        matching_rsid_pmid10  = 'na'\n",
    "        matching_rsid_pmid100 = 'na'\n",
    "        top10rsid             = 'na'\n",
    "        top10mesh             = 'na'\n",
    "    else:\n",
    "        #Analyze metrics with \"groupby.describe\" method\n",
    "\n",
    "        ## 1. groupby.describe analysis by [rsid]\n",
    "        dfmatch_less_rsid = dfmatch_less.groupby('rsid').describe().reset_index()\n",
    "        dfmatch_less_rsid.columns = dfmatch_less_rsid.columns.to_flat_index()\n",
    "        new_column_names = ['rsid', 'pmid-count', 'pmid-unique','pmid-top','pmid-freq','mesh-count', 'mesh-unique','mesh-top','mesh-freq']\n",
    "        dfmatch_less_rsid.columns = new_column_names\n",
    "\n",
    "        ### statistics:\n",
    "        matching_rsid_pmid10 = len(dfmatch_less_rsid[dfmatch_less_rsid['pmid-unique']>10])\n",
    "        matching_rsid_pmid100 = len(dfmatch_less_rsid[dfmatch_less_rsid['pmid-unique']>100])\n",
    "\n",
    "        ### sorting, top10\n",
    "        dfmatch_less_rsidless = dfmatch_less_rsid[['rsid','pmid-unique','mesh-unique']]\n",
    "        dfmatch_less_rsidlesssort = dfmatch_less_rsidless.sort_values(by='pmid-unique', ascending= False).reset_index(drop=True)\n",
    "        top10rsid = dfmatch_less_rsidlesssort['rsid'][:10].tolist()\n",
    "        #------------------\n",
    "\n",
    "        ## 2. groupby.describe analysis by [mesh]\n",
    "        dfmatch_less_mesh = dfmatch_less.groupby('mesh').describe().reset_index()\n",
    "        dfmatch_less_mesh.columns = dfmatch_less_mesh.columns.to_flat_index()\n",
    "        # simplify df.groupby.describe, convert Multicolumn to single column \n",
    "        new_column_names = ['mesh', 'pmid-count', 'pmid-unique','pmid-top','pmid-freq','rsid-count', 'rsid-unique','rsid-top','rsid-freq']\n",
    "        dfmatch_less_mesh.columns = new_column_names\n",
    "        dfmatch_less_mesh_less = dfmatch_less_mesh[['mesh','pmid-unique','rsid-unique']]\n",
    "\n",
    "        ### add frequency, top10\n",
    "        samplepmid_count = len(dfmatch.pmids.drop_duplicates())\n",
    "        dfmatch_less_mesh_less_frq = dfmatch_less_mesh_less.copy()\n",
    "        mesh_frq = dfmatch_less_mesh_less_frq.loc[:,'pmid-unique'].astype(float)/samplepmid_count\n",
    "        dfmatch_less_mesh_less_frq.loc[:,'mesh frequency'] = round(mesh_frq,3)#*100\n",
    "        dfmatch_less_mesh_less_frqsort = dfmatch_less_mesh_less_frq.sort_values(by='pmid-unique',ascending=False).reset_index(drop=True)\n",
    "        top10mesh = dfmatch_less_mesh_less_frqsort['mesh'][:10].tolist()\n",
    "        #------------------\n",
    "\n",
    "        if save_plot:\n",
    "            # create a scatter plot\n",
    "            x = dfmatch_less_mesh_less_frqsort['mesh'].head(30)\n",
    "            y = dfmatch_less_mesh_less_frqsort['pmid-unique'].head(30)\n",
    "            plt.figure(figsize=(5, 8))\n",
    "            plt.title('Scatter Plot: '+gene+' pmid-mesh (filtered)', loc='center',pad=10)\n",
    "            plt.scatter(y, x)\n",
    "            plt.gca().invert_yaxis()\n",
    "            #plt.subplots_adjust(left=0.3, right=0.9, bottom=0.3, top=0.9)\n",
    "            #plt.xticks(rotation=90)\n",
    "            plt.tick_params(axis='x', which='both', top=True, bottom=False, labeltop=True, labelbottom=False)\n",
    "            plt.xlabel('pmid count', position=(0.5, 1.08))\n",
    "            ax = plt.gca()\n",
    "            ax.xaxis.set_label_position('top')\n",
    "            #plt.show()\n",
    "            plt.savefig(directory+'/'+gene+'_mesh_plot_'+timestamp+'_filtered.png',dpi=120, bbox_inches = \"tight\")\n",
    "            plt.close()\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "\n",
    "    # Collect REPORT data ------------------------------------------------------------------\n",
    "\n",
    "    report = { 'reference_mesh': ref_mesh_n,\n",
    "               'starting_pmidmesh': starting_pmidmesh,\n",
    "               'starting_pmid' : starting_pmid,\n",
    "               'starting_mesh': starting_mesh,\n",
    "               'starting_rsid': lit1_rsid,\n",
    "               'matching_pmidmesh': matching_pmidmesh,\n",
    "               'matching_pmids': matching_pmids,\n",
    "               'matching_mesh': matching_mesh,\n",
    "               'matching_rsid': matching_rsid,\n",
    "               'dropped_rsid': dropped_rsid,\n",
    "               'matching_mesh_ratio': round((matching_mesh/starting_mesh),3),\n",
    "               'matching_pmids_ratio': round((matching_pmids/starting_pmid),3),\n",
    "               'matching_pmidmesh_ratio':  0, #round((matching_pmidmesh/starting_pmidmesh),3),\n",
    "               'matching_rsid_ratio': round((matching_rsid/lit1_rsid),3),\n",
    "               'matching_rsid_pmid10': matching_rsid_pmid10,\n",
    "               'matching_rsid_pmid100': matching_rsid_pmid100,\n",
    "               'matching_top10mesh':str(top10mesh),\n",
    "               'matching_top10rsid':str(top10rsid),\n",
    "               }\n",
    "\n",
    "\n",
    "    # WRITE REPORT ------------\n",
    "    df_report = pd.DataFrame(report, index=[gene]).transpose()\n",
    "    df_report_complete = pd.concat([df_report_complete, df_report], axis=1)\n",
    "\n",
    "    full_runtime = datetime.now() - time_alpha\n",
    "    #print((gene+'_runtime:').ljust(18)+ str(full_runtime).ljust(15), ' Genes processed:', genes.index(gene), 'on', len(genes))\n",
    "    total_seconds = full_runtime.total_seconds()\n",
    "\n",
    "    # save checkpoint----------------------\n",
    "    if genes.index(gene) > 1 and genes.index(gene) % checkpoint == 0:\n",
    "        df_report_complete.to_csv(directory+'/GRPMX_report.csv')\n",
    "        #print(\"saved checkpoint\")\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "\n",
    "# Save report csv\n",
    "df_report_complete.to_csv(directory+'/GRPMX_report.csv')\n",
    "\n",
    "# #Update gene values (remove previous gene entry)\n",
    "GRPMX_report = pd.read_csv(directory+'/GRPMX_report.csv', index_col=0)\n",
    "time_load_1 = datetime.now()\n",
    "for gene in grpm_genes_list:\n",
    "    if gene+'.1' in GRPMX_report.columns:\n",
    "        GRPMX_report = GRPMX_report.drop(columns = gene)\n",
    "        GRPMX_report = GRPMX_report.rename(columns={gene+'.1': gene})\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "print(datetime.now() - time_load_1)\n",
    "GRPMX_report.to_csv(directory+'/GRPMX_report.csv')\n",
    "\n",
    "time_finish = datetime.now()\n",
    "time_batch = time_finish - time_alpha\n",
    "\n",
    "if os.path.isfile('run_time.txt'):\n",
    "    with open('run_time.txt', 'a') as file:\n",
    "        file.write(topic_tag+':\\n\\ttime batch: '+str(time_batch)+'\\n\\truntime/gene: '+str(time_batch/len(genes))+'\\n\\n')\n",
    "else:\n",
    "    with open('run_time.txt', 'w') as file:\n",
    "        file.write(topic_tag+':\\n\\ttime batch: '+str(time_batch)+'\\n\\truntime/gene: '+str(time_batch/len(genes))+'\\n\\n')\n",
    "\n",
    "print('time batch:',time_batch)\n",
    "print('runtime/gene:', time_batch/len(genes))"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "OB-BMI\n",
    "time batch: 0:49:12.796552\n",
    "runtime/gene: 0:00:00.190270\n",
    "\n",
    "OB-BMI (correct)\n",
    "time batch: 1:00:59.967684\n",
    "runtime/gene: 0:00:00.235838\n",
    "\n",
    "OB-BMI (pmidmesh)\n",
    "time batch: 0:42:36.831920\n",
    "runtime/gene: 0:00:00.164755"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save checkpoint\n",
    "df_report_complete.to_csv(directory+'/GRPMX_report.csv')\n",
    "\n",
    "restart_from = len(df_report_complete.T)\n",
    "print('partial job, genes in survey '+topic_tag+' report:', restart_from)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_report_complete.T.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pd.read_csv(directory+'/GRPMX_report.csv').T.head(20)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_read = pd.read_csv(directory+'/grpmx_filtered_output.csv', index_col=0)#.gene.drop_duplicates()\n",
    "#df_read.to_clipboard()\n",
    "print('genes matching:', df_read.gene.nunique())\n",
    "print('mesh matching:', df_read.mesh.nunique())\n",
    "print('apply threshold in Analyzer Module')\n",
    "df_read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize GRPMX_report.csv\n",
    "GRPMX_report = pd.read_csv(directory+'/GRPMX_report.csv', index_col=0).transpose().reset_index().rename(columns={'index':'gene'})\n",
    "GRPMX_report.gene.drop_duplicates().to_clipboard()\n",
    "print('Genes matching:',len(GRPMX_report.gene.drop_duplicates()))\n",
    "\n",
    "GRPMX_report[['reference_mesh', 'starting_pmidmesh', 'starting_pmid','starting_mesh','starting_rsid', 'matching_pmidmesh', 'matching_pmids', 'matching_mesh','matching_rsid', 'dropped_rsid']] = GRPMX_report[['reference_mesh', 'starting_pmidmesh', 'starting_pmid','starting_mesh','starting_rsid', 'matching_pmidmesh', 'matching_pmids', 'matching_mesh','matching_rsid', 'dropped_rsid']].astype(int)\n",
    "\n",
    "GRPMX_report[['matching_mesh_ratio', 'matching_pmids_ratio','matching_pmidmesh_ratio', 'matching_rsid_ratio']] = GRPMX_report[['matching_mesh_ratio', 'matching_pmids_ratio','matching_pmidmesh_ratio','matching_rsid_ratio']].astype(float)\n",
    "\n",
    "columns_to_keep = ['matching_pmids','matching_pmids_ratio','matching_mesh','matching_rsid']\n",
    "GRPMX_report_less = GRPMX_report[columns_to_keep]\n",
    "\n",
    "sorting_column = 'matching_pmids'\n",
    "GRPMX_report_sort = GRPMX_report.sort_values(by=sorting_column, ascending=False)\n",
    "\n",
    "columns_to_display = ['gene', 'matching_pmidmesh', 'matching_pmids',\n",
    "                      'matching_mesh', 'matching_rsid', 'dropped_rsid', 'matching_mesh_ratio',\n",
    "                      'matching_pmids_ratio', 'matching_pmidmesh_ratio',\n",
    "                      'matching_rsid_ratio']\n",
    "GRPMX_report_display = GRPMX_report[columns_to_display]\n",
    "GRPMX_report_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Matching PMIDs in Database\n",
    "GRPMX_report_sort = GRPMX_report.sort_values(by= 'matching_pmids',ascending=False)\n",
    "\n",
    "x = GRPMX_report_sort.gene.iloc[:40]\n",
    "y = GRPMX_report_sort['matching_pmids'].iloc[:40]\n",
    "plt.figure(figsize=(5, len(x)*0.2))\n",
    "plt.title('Matching PMIDs in Database', loc='center',pad=10)\n",
    "\n",
    "plt.barh(x,y)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tick_params(axis='x', which='both', top=True, bottom=False, labeltop=True, labelbottom=False)\n",
    "#plt.xlabel('pmid count', position=(0.5, 1.08))\n",
    "plt.ylabel('genes')\n",
    "plt.xlabel('matching pmid', position=(0.5, 1.08))\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_label_position('top')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add \"interest value\" to report:----------------------------------------------------------\n",
    "max_match_pmids = int(GRPMX_report['matching_pmids'].max())\n",
    "GRPMX_report_int = GRPMX_report\n",
    "GRPMX_report_int['matching_pmids_score'] = round((GRPMX_report_int['matching_pmids']/max_match_pmids),3)\n",
    "\n",
    "GRPMX_report_int['interest_value'] = round(GRPMX_report_int['matching_pmids_score'] * GRPMX_report_int['matching_pmids_ratio'],3)\n",
    "\n",
    "GRPMX_report_int.set_index('gene').sort_values(by='interest_value')#.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Matching PMIDs in Database\n",
    "GRPMX_report_sort = GRPMX_report.sort_values(by= 'matching_pmids_index',ascending=False)\n",
    "\n",
    "x = GRPMX_report_sort.gene.iloc[:100]\n",
    "y = GRPMX_report_sort['matching_pmids_index'].iloc[:100]\n",
    "plt.figure(figsize=(5, len(x)*0.2))\n",
    "plt.title('Matching PMIDs in Database', loc='center',pad=10)\n",
    "\n",
    "plt.barh(x,y)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tick_params(axis='x', which='both', top=True, bottom=False, labeltop=True, labelbottom=False)\n",
    "#plt.xlabel('pmid count', position=(0.5, 1.08))\n",
    "plt.ylabel('genes')\n",
    "plt.xlabel('matching pmid', position=(0.5, 1.08))\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_label_position('top')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Extra"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Simple GRPM Subsetting"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "grpm_dataset.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## filter by mesh"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# filtering source dataset\n",
    "import time\n",
    "timea = time.time()\n",
    "\n",
    "my_mesh = 'Heart Failure'\n",
    "#nbib_subset = pd.DataFrame(columns= nbib_dataset.columns)\n",
    "filteres_grpm = grpm_dataset[grpm_dataset.mesh == my_mesh].reset_index(drop=True)\n",
    "\n",
    "print((time.time()-timea)/60,'minutes')\n",
    "filteres_grpm.to_csv('filteres_grpm_heart_fail.csv') #= pd.read_csv(filteres_grpm)\n",
    "filteres_grpm"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# import LitVat-PubMed Dataset (GRPM)\n",
    "filteres_grpm = pd.read_csv('filteres_grpm_heart_fail.csv', index_col=0)\n",
    "filteres_grpm.pmids = filteres_grpm.pmids.astype('str')  # convert PMIDs to str\n",
    "filteres_grpm"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Analyze data with \"groupby.describe\" method\n",
    "\n",
    "## 1. groupby.describe analysis by [pmids]\n",
    "filteres_grpm_gene = filteres_grpm.groupby('gene').describe().reset_index()#.reset_index(drop=True)\n",
    "filteres_grpm_gene[['gene','pmids']].sort_values(by=('pmids', 'unique'), ascending=False).reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## filter by gene"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# filtering source dataset\n",
    "import time\n",
    "timea = time.time()\n",
    "my_mesh = ref.mesh[0]\n",
    "my_gene = 'GLA'\n",
    "#nbib_subset = pd.DataFrame(columns= nbib_dataset.columns)\n",
    "filteres_grpm = grpm_dataset[grpm_dataset.gene == my_gene].reset_index(drop=True)\n",
    "print((time.time()-timea)/60,'minutes')\n",
    "\n",
    "filteres_grpm.to_csv('filteres_grpm.csv') #= pd.read_csv(filteres_grpm)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# import LitVat-PubMed Dataset (GRPM)\n",
    "filteres_grpm = pd.read_csv('filteres_grpm.csv', index_col=0)\n",
    "filteres_grpm_sub = filteres_grpm[filteres_grpm.mesh.str.contains('Fabry')].reset_index(drop=True)\n",
    "filteres_grpm_sub.pmids = filteres_grpm.pmids.astype('str')  # convert PMIDs to str\n",
    "filteres_grpm_sub"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Analyze data with \"groupby.describe\" method\n",
    "\n",
    "## 1. groupby.describe analysis by [pmids]\n",
    "filteres_grpm_sub_pmids = filteres_grpm.groupby('pmids').describe().reset_index()\n",
    "filteres_grpm_sub_pmids"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "## 1. groupby.describe analysis by [rsid]\n",
    "filteres_grpm_sub_rsid = filteres_grpm.groupby('rsid').describe().reset_index()\n",
    "filteres_grpm_sub_rsid"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "## 1. groupby.describe analysis by [rsid]\n",
    "filteres_grpm_mesh = filteres_grpm.groupby('mesh').describe().reset_index()\n",
    "filteres_grpm_mesh"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "filteres_grpm_[filteres_grpm_.mesh.str.contains('Fabry')]"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "filteres_grpm_.columns = filteres_grpm_.columns.to_flat_index()\n",
    "#new_column_names = ['rsid', 'pmid-count', 'pmid-unique','pmid-top','pmid-freq','mesh-count', 'mesh-unique','mesh-top','mesh-freq']\n",
    "filteres_grpm_.columns = filteres_grpm_\n",
    "#------------------\n",
    "filteres_grpm_"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import json\n",
    "pmid_list =[]\n",
    "\n",
    "for  pmid_id  in myjson.elemento[0]:\n",
    "    pmid_list.append(pmid_id)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
