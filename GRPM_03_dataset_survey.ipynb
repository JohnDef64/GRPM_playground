{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRPM MeSH Screening \n",
    "\n",
    "This notebook is engineered to screen the previously retrieved genetic polymorphism data using selected MeSH terms. It works with MeSH sets that are used as hooks to retrieve subsets of genes and polymorphisms from the \"GRPM ds\" dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#Only for Google Colab\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# @markdown Run in Colab virtual machine by default\n",
    "\n",
    "# @markdown to run in google drive set:\n",
    "import_mydrive = False #@param {type:\"boolean\"}\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    if import_mydrive:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "        if os.path.exists('/content/drive/MyDrive/grpm_system/'):\n",
    "            %cd /content/drive/MyDrive/grpm_system/\n",
    "        else:\n",
    "            %mkdir /content/drive/MyDrive/grpm_system/\n",
    "            %cd /content/drive/MyDrive/grpm_system/\n",
    "    else:\n",
    "        if os.path.exists('/content/grpm_system/'):\n",
    "            %cd /content/grpm_system/\n",
    "        else:\n",
    "            %mkdir /content/grpm_system/\n",
    "            %cd /content/grpm_system/\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "print(\"Current working directory:\", current_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import glob\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "def simple_bool(message):\n",
    "    choose = input(message+\" (y/n): \").lower()\n",
    "    your_bool = choose in [\"y\", \"yes\",\"yea\",\"sure\"]\n",
    "    return your_bool\n",
    "\n",
    "def get_and_extract(file, dir = os.getcwd()):\n",
    "    url = \"https://zenodo.org/record/8205724/files/\"+file+\".zip?download=1\"\n",
    "    zip_file_name = file+\".zip\"\n",
    "    extracted_folder_name = dir\n",
    "\n",
    "    # Download the ZIP file\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        # Extract the ZIP contents\n",
    "        with io.BytesIO(response.content) as zip_buffer:\n",
    "            with zipfile.ZipFile(zip_buffer, 'r') as zip_ref:\n",
    "                zip_ref.extractall(extracted_folder_name)\n",
    "        print(f\"ZIP file '{zip_file_name}' extracted to '{extracted_folder_name}' successfully.\")\n",
    "    else:\n",
    "        print(\"Failed to download the ZIP file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Get GRPM Dataset from Zenodo Repository\n",
    "#https://zenodo.org/record/8205724  DOI: 10.5281/zenodo.8205724\n",
    "\n",
    "if simple_bool('Download pre-made GRPM-Dataset from Zenodo? (6.5 minutes in Colab)'):\n",
    "    timea = datetime.now()\n",
    "    get_and_extract('grpm_dataset')\n",
    "    print('Download and extraction time ',datetime.now()-timea)\n",
    "\n",
    "if simple_bool('Download pre-made ref-mesh-archive from Zenodo?'):\n",
    "    timea = datetime.now()\n",
    "    get_and_extract('ref-mesh-archive')\n",
    "    print('Download and extraction time ',datetime.now()-timea)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import GRPM dataset (required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#Load GRPM db Report-----------------------------------------\n",
    "\n",
    "# choose database:\n",
    "db_tag      = 'pcg'\n",
    "# 'pcg'    = protein coding genes = grpm_db\n",
    "# 'rna'    = rna genes            = grpm_db_rna\n",
    "# 'pseudo' = pseudogenes          = grpm_db_pseudo\n",
    "\n",
    "db_name = 'grpm_db_'+ db_tag\n",
    "db_path = 'grpm_dataset/'+db_name\n",
    "\n",
    "print('importing GRPM Dataset...')\n",
    "#get gene list from grpm report\n",
    "GRPM_report = pd.read_csv(db_path+'/GRPM_report.csv',index_col=0).transpose().reset_index().rename(columns={'index':'gene'})\n",
    "grpm_genes_list = GRPM_report.gene.to_list()\n",
    "\n",
    "#Import grpm data back-------------------------------------------\n",
    "time_load_1 = datetime.now()\n",
    "\n",
    "columns = ['gene', 'rsid', 'pmids', 'mesh']\n",
    "dummy = pd.read_csv(db_path+'/grpm_table_output.csv', usecols=columns)\n",
    "\n",
    "dummy['pmids'] = dummy['pmids'].astype(str) #convert pmid type in str\n",
    "time_load_2 = datetime.now()\n",
    "print('time load:',time_load_2-time_load_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Subset GRPM Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "subset_grpm = simple_bool('Do you want to use a custom gene list to subset GRPM Dataset?')\n",
    "if subset_grpm:\n",
    "    # import your custom gene list (.csv)\n",
    "    file_csv = []\n",
    "    for file in os.listdir():\n",
    "        if file.endswith(\".csv\") or file.endswith(\".tsv\"):\n",
    "            file_csv.append(file)\n",
    "\n",
    "    filenum = input('import your custom gene list (.csv)\\nselect file index: \\n'+str(pd.Series(file_csv)))\n",
    "\n",
    "    subset_genes = pd.read_csv(file_csv[int(filenum)])\n",
    "    subset_genes = subset_genes[subset_genes.columns[int(input('select column index:\\n'+ str(pd.Series(subset_genes.columns))))]].drop_duplicates()\n",
    "\n",
    "    time1 = datetime.now()\n",
    "    subset_genes = GRPM_report.sample(frac=0.001).gene.to_list()\n",
    "\n",
    "    # subsetting GRPM_report and dummy\n",
    "    GRPM_report_subset = GRPM_report[GRPM_report['gene'].isin(subset_genes)]\n",
    "    dummy_subset = dummy[dummy['gene'].isin(subset_genes)]\n",
    "    print(\"You're using a GRPM Dataset partition\\ntime subsetting:\",time_load_2-time_load_1)\n",
    "    display(GRPM_report_subset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define context\n",
    "    - gene list\n",
    "    - survey directory\n",
    "    - ref-mesh list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check avalable ref-MeSH lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#Check avalable refs:\n",
    "ref_path = \"ref-mesh-archive/\"  # Replace with the actual ref mesh path\n",
    "\n",
    "#---------------------------------\n",
    "#use random mesh list?\n",
    "random_mesh = False\n",
    "if random_mesh:\n",
    "    ref_path = \"ref-mesh-archive/random_lists/\"\n",
    "#---------------------------------\n",
    "\n",
    "# Create a file path pattern to match CSV files\n",
    "file_pattern = os.path.join(ref_path, \"*.csv\")\n",
    "\n",
    "# Use glob to get a list of file paths matching the pattern\n",
    "csv_files = glob.glob(file_pattern)\n",
    "\n",
    "csv_files_name = []\n",
    "# Print the list of CSV files\n",
    "for file in csv_files:\n",
    "    file_name = os.path.basename(file)\n",
    "    csv_files_name.append(file_name)\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "print('Available reference mesh lists:')\n",
    "csv_files_df = pd.Series(csv_files_name)\n",
    "\n",
    "csv_file_tag = pd.DataFrame()\n",
    "if not random_mesh:\n",
    "    csv_file_tag = csv_files_df.str.extract(r'ref_mesh_(.*)\\.csv', expand=False).dropna().reset_index(drop=True)\n",
    "else:\n",
    "    csv_file_tag = csv_files_df.str.extract(r'(.*)\\.csv', expand=False).dropna().reset_index(drop=True)\n",
    "\n",
    "csv_file_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set directory/import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------\n",
    "# define directory folder path:\n",
    "survey_path = 'grpm_surveys/' # keep default to use root path\n",
    "\n",
    "# choose ref_mesh.csv tab:\n",
    "print('choose index from available ref mesh list:')\n",
    "topic_tag   = csv_file_tag[int(input(csv_file_tag))] \n",
    "add         = ''    # additional survey directory tag\n",
    "\n",
    "#------------------------------------------------------\n",
    "\n",
    "# (1) Create survey directory:\n",
    "survey_path = survey_path+'grpm_random/' if random_mesh else survey_path\n",
    "directory = survey_path + 'grpm_survey_' + db_tag + '_' + topic_tag + add\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# (2) Import Mesh-reference list:\n",
    "ref_filename = \"ref_mesh_\" + topic_tag + \".csv\" if not random_mesh else topic_tag + \".csv\"\n",
    "ref = pd.read_csv(ref_path + ref_filename, index_col=0)\n",
    "\n",
    "if 'mesh' not in ref.columns:\n",
    "    ref = ref.rename(columns={'Preferred Label': 'mesh'})\n",
    "\n",
    "ref_mesh_n = ref.mesh.nunique()\n",
    "ref_mesh_list = ref['mesh'].drop_duplicates()\n",
    "\n",
    "# (3) Load saved checkpoint data or initialize dataframes:\n",
    "if os.path.isfile(directory+'/grpmx_filtered_output.csv'):\n",
    "    complete_df = pd.read_csv(directory+'/grpmx_filtered_output.csv',index_col=0)\n",
    "else:\n",
    "    complete_df = pd.DataFrame()\n",
    "\n",
    "if os.path.isfile(directory+'/GRPMX_report.csv'):\n",
    "    df_report_complete = pd.read_csv(directory+'/GRPMX_report.csv',index_col=0)\n",
    "    restart = True\n",
    "else:\n",
    "    df_report_complete = pd.DataFrame()\n",
    "    restart = False\n",
    "#----------------------------------------------------------\n",
    "print('\\n', ref_mesh_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# check checkpoint report:\n",
    "df_report_complete.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#---------------------------------------------\n",
    "# Edit saving options:\n",
    "save_plot = False\n",
    "checkpoint = 200 #save data each x genes\n",
    "\n",
    "run_sample = False # set True just to run a test\n",
    "num_sample = 10\n",
    "\n",
    "partial_job = False # set True to set job end point\n",
    "partial_job_finish = 10\n",
    "\n",
    "exclude_top10 = True # for a faster job\n",
    "#---------------------------------------------\n",
    "\n",
    "time_start = datetime.now()\n",
    "\n",
    "if restart:\n",
    "    restart_from = len(df_report_complete.T)\n",
    "    gene_start = restart_from\n",
    "    print('search restarted from '+str(restart_from))\n",
    "else:\n",
    "    gene_start = 0\n",
    "\n",
    "# Ddefine grpm subset\n",
    "if subset_grpm:\n",
    "    GRPM_report = GRPM_report_subset\n",
    "    dummy = dummy_subset\n",
    "\n",
    "# define gene list\n",
    "import random\n",
    "if run_sample:\n",
    "    genes = random.sample(grpm_genes_list[:], num_sample)\n",
    "else:\n",
    "    if partial_job:\n",
    "        genes = grpm_genes_list[gene_start: gene_start + partial_job_finish]\n",
    "    else:\n",
    "        genes = grpm_genes_list[gene_start:len(grpm_genes_list)]\n",
    "\n",
    "for gene in genes:\n",
    "\n",
    "    time_alpha = datetime.now()\n",
    "    timestamp = time_alpha.strftime('%Y%m%d%H%M%S')\n",
    "\n",
    "    if gene in dummy.gene.drop_duplicates().to_list():\n",
    "\n",
    "        dummy_gene = dummy.loc[dummy['gene'] == gene]\n",
    "        rsidpmid = dummy_gene[['rsid','pmids']].drop_duplicates().reset_index(drop=True)\n",
    "        pmidmesh = dummy_gene[['pmids','mesh']].drop_duplicates()\n",
    "        #dfmesh = dummy_gene[['pmids', 'mesh', 'qualifier', 'major']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "        #Filter pmid for rsid with pmid>1 [Deprecated]\n",
    "        #   rsidpmid_count = rsidpmid.groupby('rsid').describe().reset_index()\n",
    "        #   rsidpmid_count.columns = rsidpmid_count.columns.to_flat_index()\n",
    "        #   new_column_names = ['rsid', 'pmid_count', 'pmid_unique','pmid_top','pmid_freq']\n",
    "        #   rsidpmid_count.columns = new_column_names\n",
    "        #   outless = rsidpmid_count[rsidpmid_count.pmid_unique>1]\n",
    "        #   mask = rsidpmid['rsid'].isin(outless.rsid)\n",
    "        #   rsidpmid_less = rsidpmid[mask]\n",
    "\n",
    "\n",
    "        # Correlation on \"pmidmesh.mesh\"------------------------\n",
    "        mask = pmidmesh['mesh'].isin(ref_mesh_list)\n",
    "        dfmatch = pmidmesh[mask]\n",
    "        mask_full = dummy_gene['mesh'].isin(ref_mesh_list)\n",
    "        dfmatch_full = dummy_gene[mask_full]\n",
    "        #report statistics:\n",
    "        pmidmesh_before  =  pmidmesh.nunique()\n",
    "        pmidmesh_after   =  dfmatch.nunique()\n",
    "        interesting_pmid =  dfmatch.nunique()\n",
    "\n",
    "        #pmidmask = rsidpmid['pmids'].isin(dfmatch.pmids) #mymask\n",
    "        #rsidlast = rsidpmid[pmidmask]  # mask on rsidpmid\n",
    "        #rsidlastlist = rsidlast.rsid.drop_duplicates()\n",
    "\n",
    "        #report statistics\n",
    "        lit1_rsid         = dummy_gene.rsid.nunique()\n",
    "        #lit1_pmid_f      = rsidpmid_less.pmids.nunique()\n",
    "        matching_rsid     = dfmatch_full['rsid'].nunique()\n",
    "        dropped_rsid      = lit1_rsid - dfmatch_full['rsid'].nunique()\n",
    "        starting_pmid     = pmidmesh['pmids'].nunique()\n",
    "        starting_mesh     = pmidmesh['mesh'].nunique()\n",
    "        starting_pmidmesh = len(pmidmesh)\n",
    "        matching_pmids    = dfmatch.pmids.nunique()\n",
    "        matching_mesh     = dfmatch.mesh.nunique()\n",
    "        matching_pmidmesh = len(dfmatch)\n",
    "\n",
    "\n",
    "        dfmatch_less_ = dfmatch_full[['pmids', 'rsid', 'mesh']].drop_duplicates()\n",
    "        #interesting_rsid = dfmatch_less_.rsid.nunique()\n",
    "\n",
    "        #------------------------\n",
    "        if exclude_top10:\n",
    "            matching_rsid_pmid10  = 'missing'\n",
    "            matching_rsid_pmid100 = 'missing'\n",
    "            top10rsid             = 'missing'\n",
    "            top10mesh             = 'missing'\n",
    "        else:\n",
    "            #Analyze enrichment with \"groupby.describe\" method\n",
    "\n",
    "            ## 1. groupby.describe analysis by [rsid]\n",
    "            dfmatch_less_rsid = dfmatch_less_.groupby('rsid').describe().reset_index()\n",
    "            dfmatch_less_rsid.columns = dfmatch_less_rsid.columns.to_flat_index()\n",
    "            new_column_names = ['rsid', 'pmid-count', 'pmid-unique','pmid-top','pmid-freq','mesh-count', 'mesh-unique','mesh-top','mesh-freq']\n",
    "            dfmatch_less_rsid.columns = new_column_names\n",
    "\n",
    "            ### statistics:\n",
    "            matching_rsid_pmid10 = len(dfmatch_less_rsid[dfmatch_less_rsid['pmid-unique']>10])\n",
    "            matching_rsid_pmid100 = len(dfmatch_less_rsid[dfmatch_less_rsid['pmid-unique']>100])\n",
    "\n",
    "            ### sorting, top10\n",
    "            dfmatch_less_rsidless = dfmatch_less_rsid[['rsid','pmid-unique','mesh-unique']]\n",
    "            dfmatch_less_rsidlesssort = dfmatch_less_rsidless.sort_values(by='pmid-unique', ascending= False).reset_index(drop=True)\n",
    "            top10rsid = dfmatch_less_rsidlesssort['rsid'][:10].tolist()\n",
    "            #------------------\n",
    "\n",
    "            ## 2. groupby.describe analysis by [mesh]\n",
    "            dfmatch_less_mesh = dfmatch_less_.groupby('mesh').describe().reset_index()\n",
    "            dfmatch_less_mesh.columns = dfmatch_less_mesh.columns.to_flat_index()\n",
    "            #to handle generate df.groupby.describe, convert Multicolumn to single column\n",
    "            #https://datascientyst.com/flatten-multiindex-in-pandas/\n",
    "            new_column_names = ['mesh', 'pmid-count', 'pmid-unique','pmid-top','pmid-freq','rsid-count', 'rsid-unique','rsid-top','rsid-freq']\n",
    "            dfmatch_less_mesh.columns = new_column_names\n",
    "\n",
    "            dfmatch_less_mesh_less = dfmatch_less_mesh[['mesh','pmid-unique','rsid-unique']]\n",
    "            #dfmatch_less_mesh_lesssort = dfmatch_less_mesh_less.sort_values(by='pmid-unique',ascending=False).reset_index(drop=True)\n",
    "\n",
    "            ### add frequency, top10\n",
    "            samplepmid_count = len(dfmatch.pmids.drop_duplicates())\n",
    "            dfmatch_less_mesh_less_frq = dfmatch_less_mesh_less.copy()\n",
    "            mesh_frq = dfmatch_less_mesh_less_frq.loc[:,'pmid-unique'].astype(float)/samplepmid_count\n",
    "            dfmatch_less_mesh_less_frq.loc[:,'mesh frequency'] = round(mesh_frq,3)#*100\n",
    "            dfmatch_less_mesh_less_frqsort = dfmatch_less_mesh_less_frq.sort_values(by='pmid-unique',ascending=False).reset_index(drop=True)\n",
    "            top10mesh = dfmatch_less_mesh_less_frqsort['mesh'][:10].tolist()\n",
    "        #------------------\n",
    "\n",
    "        if save_plot:\n",
    "            # create a scatter plot\n",
    "            x = dfmatch_less_mesh_less_frqsort['mesh'].head(30)\n",
    "            y = dfmatch_less_mesh_less_frqsort['pmid-unique'].head(30)\n",
    "            plt.figure(figsize=(5, 8))\n",
    "            plt.title('Scatter Plot: '+gene+' pmid-mesh (filtered)', loc='center',pad=10)\n",
    "            plt.scatter(y, x)\n",
    "            plt.gca().invert_yaxis()\n",
    "            #plt.subplots_adjust(left=0.3, right=0.9, bottom=0.3, top=0.9)\n",
    "            #plt.xticks(rotation=90)\n",
    "            plt.tick_params(axis='x', which='both', top=True, bottom=False, labeltop=True, labelbottom=False)\n",
    "            plt.xlabel('pmid count', position=(0.5, 1.08))\n",
    "            ax = plt.gca()\n",
    "            ax.xaxis.set_label_position('top')\n",
    "            #plt.show()\n",
    "            plt.savefig(directory+'/'+gene+'_mesh_plot_'+timestamp+'_filtered.png',dpi=120, bbox_inches = \"tight\")\n",
    "            plt.close()\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        #STORE DATA----------------------------------------------------------------------\n",
    "        #timestamp = time2.strftime('%Y%m%d%H%M%S')\n",
    "\n",
    "        #screening results:\n",
    "        dfmatch_less_['gene'] = gene\n",
    "        complete_df = pd.concat([complete_df, dfmatch_less_])\n",
    "\n",
    "\n",
    "        #REPORT------------------------------------------------------------------\n",
    "\n",
    "        report = { 'reference_mesh': ref_mesh_n,\n",
    "                   #'filtered_pmidmesh': pmidmesh_after,\n",
    "                   #'interesting_pmid': interesting_pmid,\n",
    "                   #'interesting_rsid': interesting_rsid,\n",
    "                   'starting_pmidmesh': starting_pmidmesh,\n",
    "                   'starting_pmid' : starting_pmid,\n",
    "                   'starting_mesh': starting_mesh,\n",
    "                   'starting_rsid': lit1_rsid,\n",
    "                   'matching_pmidmesh': matching_pmidmesh,\n",
    "                   'matching_pmids': matching_pmids,\n",
    "                   'matching_mesh': matching_mesh,\n",
    "                   'matching_rsid': matching_rsid,\n",
    "                   'dropped_rsid': dropped_rsid,\n",
    "                   'matching_mesh_ratio': round((matching_mesh/starting_mesh),3),\n",
    "                   'matching_pmids_ratio': round((matching_pmids/starting_pmid),3),\n",
    "                   'matching_pmidmesh_ratio': round((matching_pmidmesh/starting_pmidmesh),3),\n",
    "                   'matching_rsid_ratio': round((matching_rsid/lit1_rsid),3),\n",
    "                   'matching_rsid_pmid10': matching_rsid_pmid10,\n",
    "                   'matching_rsid_pmid100': matching_rsid_pmid100,\n",
    "                   'matching_top10mesh':str(top10mesh),\n",
    "                   'matching_top10rsid':str(top10rsid),\n",
    "                   }\n",
    "\n",
    "        df_report = pd.DataFrame(report, index=[gene]).transpose()\n",
    "\n",
    "        # SLOW STEP!----------------------\n",
    "        # generate fist report.csv\n",
    "\n",
    "        #if os.path.isfile(directory+'/GRPMX_report.csv'):\n",
    "        #    df_report_complete = pd.read_csv(directory+'/GRPMX_report.csv', index_col=0)#).set_index('Unnamed: 0')\n",
    "        #    df_report_complete = pd.concat([df_report_complete, df_report], axis=1)\n",
    "        #    df_report_complete.to_csv(directory+'/GRPMX_report.csv')\n",
    "        #else:\n",
    "        #    df_report.to_csv(directory+'/GRPMX_report.csv') # solo la prima volta\n",
    "\n",
    "        # FASTER ALT------------\n",
    "        df_report_complete = pd.concat([df_report_complete, df_report], axis=1)\n",
    "\n",
    "        time_omega = datetime.now()\n",
    "        full_runtime = time_omega - time_alpha\n",
    "        print((gene+'_runtime:').ljust(18)+ str(full_runtime).ljust(15), ' Genes processed:', genes.index(gene), 'on', len(genes))\n",
    "        total_seconds = full_runtime.total_seconds()\n",
    "\n",
    "        # save checkpoint----------------------\n",
    "        if genes.index(gene) > 1 and genes.index(gene) % checkpoint == 0:\n",
    "            complete_df = complete_df.reindex(columns=['gene','rsid', 'pmids', 'mesh'])\n",
    "            complete_df.to_csv(directory+'/grpmx_filtered_output.csv')\n",
    "            df_report_complete.to_csv(directory+'/GRPMX_report.csv')\n",
    "            print(\"saved checkpoint\")\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    else:\n",
    "        print(gene+' not present in DataBase')\n",
    "        pass\n",
    "\n",
    "# Save complete csv\n",
    "complete_df = complete_df.reindex(columns=['gene','rsid', 'pmids', 'mesh'])\n",
    "complete_df.to_csv(directory+'/grpmx_filtered_output.csv')\n",
    "\n",
    "df_report_complete.to_csv(directory+'/GRPMX_report.csv')\n",
    "\n",
    "# #Update gene values (remove previous gene entry)\n",
    "GRPMX_report = pd.read_csv(directory+'/GRPMX_report.csv', index_col=0)\n",
    "time_load_1 = datetime.now()\n",
    "for gene in grpm_genes_list:\n",
    "    if gene+'.1' in GRPMX_report.columns:\n",
    "        GRPMX_report = GRPMX_report.drop(columns = gene)\n",
    "        GRPMX_report = GRPMX_report.rename(columns={gene+'.1': gene})\n",
    "        #print(genes.index(gene))\n",
    "    else:\n",
    "        pass\n",
    "time_load_2 = datetime.now()\n",
    "print(time_load_2 - time_load_1)\n",
    "GRPMX_report.to_csv(directory+'/GRPMX_report.csv')\n",
    "\n",
    "time_finish = datetime.now()\n",
    "time_batch = time_finish - time_start\n",
    "\n",
    "if os.path.isfile('run_time.txt'):\n",
    "    with open('run_time.txt', 'a') as file:\n",
    "        file.write(topic_tag+':\\n\\ttime batch: '+str(time_batch)+'\\n\\truntime/gene: '+str(time_batch/len(genes))+'\\n\\n')\n",
    "else:\n",
    "    with open('run_time.txt', 'w') as file:\n",
    "        file.write(topic_tag+':\\n\\ttime batch: '+str(time_batch)+'\\n\\truntime/gene: '+str(time_batch/len(genes))+'\\n\\n')\n",
    "\n",
    "print('time batch:',time_batch)\n",
    "print('runtime/gene:', time_batch/len(genes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "restart"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# save checkpoint\n",
    "complete_df = complete_df.reindex(columns=['gene','rsid', 'pmids', 'mesh'])\n",
    "complete_df.to_csv(directory+'/grpmx_filtered_output.csv')\n",
    "\n",
    "df_report_complete.to_csv(directory+'/GRPMX_report.csv')\n",
    "\n",
    "restart_from = len(df_report_complete.T)\n",
    "print('partial job, genes in survey '+topic_tag+' report:', restart_from)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_report_complete.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_read = pd.read_csv(directory+'/grpmx_filtered_output.csv', index_col=0)#.gene.drop_duplicates()\n",
    "#df_read.to_clipboard()\n",
    "print('genes matching:', df_read.gene.nunique())\n",
    "print('mesh matching:', df_read.mesh.nunique())\n",
    "print('apply threshold in Analizer Module')\n",
    "df_read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Visualize GRPMX_report.csv\n",
    "GRPMX_report = pd.read_csv(directory+'/GRPMX_report.csv', index_col=0).transpose().reset_index().rename(columns={'index':'gene'})\n",
    "GRPMX_report.gene.drop_duplicates().to_clipboard()\n",
    "print(len(GRPMX_report.gene.drop_duplicates()))\n",
    "GRPMX_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "GRPMX_report[['reference_mesh', 'starting_pmidmesh', 'starting_pmid','starting_mesh','starting_rsid', 'matching_pmidmesh', 'matching_pmids', 'matching_mesh','matching_rsid', 'dropped_rsid']] = GRPMX_report[['reference_mesh', 'starting_pmidmesh', 'starting_pmid','starting_mesh','starting_rsid', 'matching_pmidmesh', 'matching_pmids', 'matching_mesh','matching_rsid', 'dropped_rsid']].astype(int)\n",
    "\n",
    "GRPMX_report[['matching_mesh_ratio', 'matching_pmids_ratio','matching_pmidmesh_ratio', 'matching_rsid_ratio']] = GRPMX_report[['matching_mesh_ratio', 'matching_pmids_ratio','matching_pmidmesh_ratio','matching_rsid_ratio']].astype(float)\n",
    "\n",
    "columns_to_keep = ['matching_pmids','matching_pmids_ratio','matching_mesh','matching_rsid']\n",
    "GRPMX_report_less = GRPMX_report[columns_to_keep]\n",
    "\n",
    "sorting_column = 'matching_pmids'\n",
    "GRPMX_report_sort = GRPMX_report.sort_values(by=sorting_column, ascending=False)\n",
    "\n",
    "columns_to_display = ['gene', 'matching_pmidmesh', 'matching_pmids',\n",
    "                      'matching_mesh', 'matching_rsid', 'dropped_rsid', 'matching_mesh_ratio',\n",
    "                      'matching_pmids_ratio', 'matching_pmidmesh_ratio',\n",
    "                      'matching_rsid_ratio']\n",
    "GRPMX_report_display = GRPMX_report[columns_to_display].T\n",
    "GRPMX_report_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Matching PMIDs in Database\n",
    "GRPMX_report_sort = GRPMX_report.sort_values(by= 'matching_pmids',ascending=False)\n",
    "\n",
    "x = GRPMX_report_sort.gene.iloc[:40]\n",
    "y = GRPMX_report_sort['matching_pmids'].iloc[:40]\n",
    "plt.figure(figsize=(5, len(x)*0.2))\n",
    "plt.title('Matching PMIDs in Database', loc='center',pad=10)\n",
    "\n",
    "plt.barh(x,y)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tick_params(axis='x', which='both', top=True, bottom=False, labeltop=True, labelbottom=False)\n",
    "#plt.xlabel('pmid count', position=(0.5, 1.08))\n",
    "plt.ylabel('genes')\n",
    "plt.xlabel('matching pmid', position=(0.5, 1.08))\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_label_position('top')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Add \"interest value\" to report:----------------------------------------------------------\n",
    "max_match_pmids = int(GRPMX_report['matching_pmids'].max())\n",
    "GRPMX_report_int = GRPMX_report\n",
    "GRPMX_report_int['matching_pmids_score'] = round((GRPMX_report_int['matching_pmids']/max_match_pmids),3)\n",
    "\n",
    "GRPMX_report_int['interest_value'] = round(GRPMX_report_int['matching_pmids_score'] * GRPMX_report_int['matching_pmids_ratio'],3)\n",
    "\n",
    "GRPMX_report_int.set_index('gene').sort_values(by='interest_value')#.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Matching PMIDs in Database\n",
    "GRPMX_report_sort = GRPMX_report.sort_values(by= 'matching_pmids_index',ascending=False)\n",
    "\n",
    "x = GRPMX_report_sort.gene.iloc[:100]\n",
    "y = GRPMX_report_sort['matching_pmids_index'].iloc[:100]\n",
    "plt.figure(figsize=(5, len(x)*0.2))\n",
    "plt.title('Matching PMIDs in Database', loc='center',pad=10)\n",
    "\n",
    "plt.barh(x,y)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tick_params(axis='x', which='both', top=True, bottom=False, labeltop=True, labelbottom=False)\n",
    "#plt.xlabel('pmid count', position=(0.5, 1.08))\n",
    "plt.ylabel('genes')\n",
    "plt.xlabel('matching pmid', position=(0.5, 1.08))\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_label_position('top')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
